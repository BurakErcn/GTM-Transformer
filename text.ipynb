{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    print(args)\n",
    "    # Seeds for reproducibility (By default we use the number 21)\n",
    "\n",
    "    # Load sales data\n",
    "    data_folder = \"./dataset/\"\n",
    "    train_df = pd.read_csv(Path(data_folder + 'train.csv'), parse_dates=['release_date'])\n",
    "    test_df = pd.read_csv(Path(data_folder + 'test.csv'), parse_dates=['release_date'])\n",
    "\n",
    "    # Load category and color encodings\n",
    "    cat_dict = torch.load(Path(data_folder + 'category_labels.pt'))\n",
    "    col_dict = torch.load(Path(data_folder + 'color_labels.pt'))\n",
    "    fab_dict = torch.load(Path(data_folder + 'fabric_labels.pt'))\n",
    "\n",
    "    print(cat_dict)\n",
    "    print(col_dict)\n",
    "    print(fab_dict)\n",
    "\n",
    "    return cat_dict, col_dict, fab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'capris': 0, 'cloak': 1, 'culottes': 2, 'doll dress': 3, 'drop sleeve': 4, 'gitana skirt': 5, 'kimono dress': 6, 'long cardigan': 7, 'long coat': 8, 'long dress': 9, 'long duster': 10, 'long skirt': 11, 'long sleeve': 12, 'longuette skirt': 13, 'maxi': 14, 'medium cardigan': 15, 'medium coat': 16, 'medium duster': 17, 'midi skirt': 18, 'miniskirt': 19, 'patterned': 20, 'printed': 21, 'sheath dress': 22, 'shirt dress': 23, 'short cardigan': 24, 'short coat': 25, 'short sleeves': 26, 'shorts': 27, 'sleeveless': 28, 'solid colours': 29, 'tracksuit': 30, 'trapeze dress': 31}\n",
      "{'yellow': 0, 'brown': 1, 'blue': 2, 'grey': 3, 'green': 4, 'black': 5, 'red': 6, 'white': 7, 'orange': 8, 'violet': 9}\n",
      "{'acrylic': 0, 'scuba crepe': 49, 'tulle': 55, 'angora': 1, 'faux leather': 14, 'georgette': 21, 'lurex': 30, 'nice': 38, 'crepe': 9, 'satin cotton': 47, 'silky satin': 51, 'fur': 20, 'matte jersey': 33, 'plisse': 43, 'velvet': 56, 'lace': 27, 'cotton': 8, 'piquet': 42, 'plush': 45, 'bengaline': 2, 'jacquard': 26, 'frise': 19, 'technical': 53, 'cady': 3, 'dark jeans': 11, 'light jeans': 28, 'ity': 25, 'plumetis': 44, 'polyviscous': 46, 'dainetto': 10, 'webbing': 58, 'foam rubber': 18, 'heavy jeans': 23, 'chanel': 5, 'marocain': 32, 'macrame': 31, 'embossed': 13, 'nylon': 39, 'tencel': 54, 'paillettes': 41, 'chambree': 4, 'chine crepe': 6, 'linen': 29, 'muslin cotton or silk': 36, 'tactel': 52, 'viscose twill': 57, 'cloth': 7, 'mohair': 35, 'mutton': 37, 'scottish': 48, 'milano stitch': 34, 'devore': 12, 'hron': 24, 'ottoman': 40, 'fluid': 16, 'flamed': 15, 'fluid polyviscous': 17, 'shiny jersey': 50, 'goose': 22}\n"
     ]
    }
   ],
   "source": [
    "cat_dict, col_dict, fab_dict = run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedder(nn.Module):\n",
    "    def __init__(self, embedding_dim, cat_dict, col_dict, fab_dict, gpu_num):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.cat_dict = {v: k for k, v in cat_dict.items()}\n",
    "        self.col_dict = {v: k for k, v in col_dict.items()}\n",
    "        self.fab_dict = {v: k for k, v in fab_dict.items()}\n",
    "        self.word_embedder = pipeline('feature-extraction', model='bert-base-uncased')\n",
    "        self.fc = nn.Linear(768, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.gpu_num = gpu_num\n",
    "\n",
    "    def forward(self, category, color, fabric):\n",
    "        textual_description = [self.col_dict[color.detach().cpu().numpy().tolist()[i]] + ' ' \\\n",
    "                + self.fab_dict[fabric.detach().cpu().numpy().tolist()[i]] + ' ' \\\n",
    "                + self.cat_dict[category.detach().cpu().numpy().tolist()[i]] for i in range(len(category))]\n",
    "        # Hafta ve maÄŸaza idsi eklenmeli.\n",
    "\n",
    "\n",
    "        # Use BERT to extract features\n",
    "        word_embeddings = self.word_embedder(textual_description)\n",
    "\n",
    "        # BERT gives us embeddings for [CLS] ..  [EOS], which is why we only average the embeddings in the range [1:-1] \n",
    "        # We're not fine tuning BERT and we don't want the noise coming from [CLS] or [EOS]\n",
    "        word_embeddings = [torch.FloatTensor(x[0][1:-1]).mean(axis=0) for x in word_embeddings] \n",
    "        word_embeddings = torch.stack(word_embeddings)\n",
    "        \n",
    "        # Embed to our embedding space\n",
    "        word_embeddings = self.dropout(self.fc(word_embeddings))\n",
    "\n",
    "        return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = TextEmbedder(32, cat_dict, col_dict, fab_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_multitrends import ZeroShotDataset\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 5080/5080 [01:35<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Starting dataset creation process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 497/497 [00:12<00:00, 40.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(Path(\"./dataset/\" + 'train.csv'), parse_dates=['release_date'])\n",
    "test_df = pd.read_csv(Path(\"./dataset/\" + 'test.csv'), parse_dates=['release_date'])\n",
    "\n",
    "gtrends = pd.read_csv(Path(\"./dataset/\" + 'gtrends.csv'), index_col=[0], parse_dates=True)\n",
    "\n",
    "train_loader = ZeroShotDataset(train_df, Path(\"./dataset/\" + '/images'), gtrends, cat_dict, col_dict,\n",
    "                                fab_dict, 52).get_loader(batch_size=128, train=True)\n",
    "test_loader = ZeroShotDataset(test_df, Path(\"./dataset/\" + '/images'), gtrends, cat_dict, col_dict,\n",
    "                                fab_dict, 52).get_loader(batch_size=1, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch\n",
    "for data in train_loader:\n",
    "    item_sales, category, color, fabric, temporal_features, gtrends, images = data \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoding = text_encoder(category, color, fabric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4262,  0.0951,  0.2404,  ..., -0.0838, -0.0697, -0.1389],\n",
       "        [ 0.2306,  0.0016, -0.0000,  ..., -0.2545,  0.0091,  0.0000],\n",
       "        [ 0.4942, -0.1109,  0.1855,  ..., -0.3408,  0.0102, -0.1013],\n",
       "        ...,\n",
       "        [ 0.5237, -0.0000,  0.0000,  ..., -0.2384,  0.0090,  0.0296],\n",
       "        [ 0.2936,  0.0143,  0.2011,  ..., -0.0000,  0.0818, -0.1738],\n",
       "        [ 0.6877,  0.0000,  0.0902,  ..., -0.2196,  0.1042, -0.1543]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_encoding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtm-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
